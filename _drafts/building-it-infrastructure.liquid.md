---
layout: post.liquid
title:  "Building IT infrastructure"
date: 2022-09-04 20:32
last_updated: 2022-09-04 20:32
tags: it infrastructure software
permalink: /building-it-infrastructure
categories: [it, infrastructure, software]
---
IT infrastructures are the substrate on which user applications run 
[[traugott98]](#traugott98). Without the users' need for applications, we wouldn't 
have to build them. In many cases, it is the success of a user application
that leads to infrastructure[^1] growth.[^2]  

[^1]: _Infrastructure_ is a 
    relative term, and it's usually to refer to those applications that support your 
    work. 

    <div style="text-align: center">
        <img width="500" 
            src="/assets/images/views-it-infra.png">
        <figcaption>Views on IT infrastructure</figcaption>
    </div>

[^2]: Are examples of the opposite? namely, 
    an application ecosystem growing because of the success of 
    successful infrastructure. 

    **Maybe it's a loop and not an arrow**: AI infrastructure
    progress was possible due to the incentive generated by teh hope
    that bigger models might perform better. So the high hopes played
    a big part in the further investment in infrastructure, however,
    it is because of the progress in AI infrastructure that models
    today are even possible. And today it is the (cost of)
    infrastructure that acts a bottleneck to building even larger
    models. So there maybe a loop from infrastructure to application
    development.


A while back I stumbled upon Traugott's article
[Bootstrapping an infrastructure](#traugott98), the article contains many ideas that 
are considered good practices today. I was not able to find direct connections between
the ideas in Traugott's article and other more recent terminology, so I decided to write 
this post and attempt to connect those ideas with their contemporary incarnations. 


## Building IT infrastructure is a development process

IT infrastructures are built to solve problems that have been identified. A first 
approach at a solution and implementation provides additional information about the 
problem, corner cases are identified and a new attempt can be then made to improve the 
solution.

Most of the time progress is made in incremental steps, building on previous success.
The process is iterative and rarely the problems or solutions are so completely new 
that they deserve to be called revolutionary or innovative. 

The pattern of making observations, generating hypotheses, building prototypes, testing 
hypotheses and measurement the difference between the desired state and the 
current state is well established in other domains of knowledge.


### IT infrastructures evolve

The needs of infrastructure users change and so the infrastructure has to be developed 
further to solve the new problems. A good accounting of all activities required to 
build infrastructure can help identify and avoid repeating mistakes. 

Building the next version of the infrastructure requires a bit of _archaeological_ work,
digging into the past to understand what decisions were made and their effects in the 
implementation.


### Version control

Contemporary implementations of version control tools teaches us about the things that 
were important to our predecessors. The fact that there's such a thing as version 
control tells us that they had the need to trace the evolution of computer programs 
and even whole infrastructures.

Today we harness the power of version control not only to record the history of all 
changes made to computer software but also to plan its future evolution. We can 
develop multiple versions simultaneously and choose the one that fits our needs 
best, an exercise in artificial selection. 

Once a good (sometimes called a "_master_") version has been built, it can be used as the 
baseline or starting point for future experimentation.


### Automation

With the help of [automation](#automation) it's possible to restore a particular state 
with relative ease. This is useful when it's necessary to change to a version 
that was more stable, or more performant or that had a different set of behaviors.

The lack of automation puts a limit to how fast we can experiment with different 
versions, as well as to how complex the infrastructure can be while still being 
manageable.


### Integration and delivery pipelines

Once the code is written and submitted to the code repository, almost every step in 
the process of delivery working software can be built into an
automated pipeline, reducing manual labor and the length of the feedback cycle.
The remaining manual steps usually consists of integrating human judgment to allow or 
reject a particular change; the pipelines are gated. 


### Infrastructure as code

Management of infrastructure was and still is a mix of manual work supplemented with 
automation. As the scale and complexity of infrastructures grows the automated approach 
becomes more and more relevant, to the point of taking the extreme position of 
encoding every aspect of managing infrastructure to enable machines to fully operate 
the infrastructure (semi-)autonomously.


### GitOps

When the infrastructure and the delivery pipelines are coded, the work of an 
engineer is confined to the operation of a version control repository and making a 
decision when a quality gate in the delivery pipelines requires human 
intervention. Git is presently a popular version control system, hence this approach 
is sometimes dubbed [GitOps](#gitops). 


## Avoid ad-hoc changes

Avoiding ad-hoc (manual) changes results in infrastructure and operations as code.

Having central code repositories where desired infrastructure state is defined. It's 
easier to manage code changes in a single place than it is to manually make the 
equivalent changes to every component that is already running. 

If configuration and operations is controlled by code changes, we can 
forbid ad-hoc changes to running infrastructure. [Immutable infrastructure](#immutable) 
grants an extra layer of protection against configuration drift.


### Making all changes code changes or _Infrastructure as Code_

Managing infrastructures involves not only physically moving hardware and cabling, 
but also significant effort in the form of writing or customizing configuration files. 
Applying configuration to multiple components efficiently is a key task in 
infrastructure management.  

Configuration files are typically text files with rigid syntax rules, a form of 
computer programming. It makes sense that infrastructure management practitioners have 
widely adopted software development practices, treating infrastructure as code. 


### Operations as Code

More and more infrastructure components are also available in virtual form, 
e.g., Software Defined Networking virtualizes all networking components making 
it easier to build whole data centers by writing code alone.

This approach is cheaper and makes it easier to evolve whole infrastructures. Not only 
hardware components can be codified, also the processes associated to their 
operation can be automated with code, it's not only Infrastructure as Code but 
Operations as Code.

Automation is expensive, but it's application pays off when the infrastructure is 
sufficiently large; changes often; or the negative effects of configuration drift are
significant.

The reduction of human effort as a result of avoiding ad-hoc changes means that labor
costs also go down. The use of Operations as Code allows a linearly growing team to manage
exponentially growing infrastructures.


<a id="immutable"></a>
### Immutable infrastructure and Disaster Recovery

Automated replacement of components can become a routine task, so long as the replaced
components are stateless. Since they don't store state they can be treated as immutable.

The easier it is to re-create a given environment, the easier it is to recover from a 
disaster. Having immutable components means they can be replaced with impunity; the 
motto is _Cattle, not pets!_, where strong attachment to specific instances of our 
components is discouraged, making replacement less painful. 


## Standardisation

The use of standard, generic components enables teams to learn more easily how to 
operate them. Generic components are also easier to fix by simply replacing the 
components using a trusted source; this kind of replacement 
is not be possible if components are configured in unique ways. 

If used in conjunction with automation, standardisation makes Disaster Recovery easier 
and faster. Realising the benefits is made easier when infrastructure configuration is 
managed as code and ad-hoc changes are avoided.  

Standardisation of components brings with it its own downsides:

> ...although the components of an infrastructure are more or less standard,
> professional architects tend to arrange them in radically different ways.
> -- [[traugott98](#traugott98)]

It's also possible to standardise the way in which generic components are used 
together. However, we must find the balance between making it easy to build quickly 
and having enough room for experimentation. 


## Component reuse

One of the biggest productivity boosters is the ability to re-use existing components, 
or solutions for common problems. Having a central repository for reusable components 
or solution templates is a time-tested approach.


### Artefact repository: storing reusable components

Another word for _components_ is _artefacts_ and which makes the purpose of an 
_Artefacts repository_ self-explanatory, it's a central place to store reusable 
components. 

Traugott refers to the central artefacts repository as the Gold Server, probably 
because that's where the golden versions of reusable components are stored.


### Gold and Golden servers

The Gold Server is not to be confused with a Golden Server. A Golden Server is 
one of many components stored in an artefact repository (Gold Server) and typically 
represents a configuration template for a virtual machine. 

The Golden Server enables clients to easily find and create copies of standard 
reusable components, including Gold Servers.


### Repeatability through component reuse and automation

Repeatability means being able to reproduce a desired state consistently, and it's 
easier to achieve when there is a library of reusable components and automated processes. 


### Automation makes errors easier to fix

Automation reduces the rate of error, or at least ensure that errors are systematic, 
making them easier to identify and fix.


### Reuse brings some costs down

Being able to build using existing standardised components and automated processes has 
the potential to reduce human labor and has the effect of bringing down the cost of 
building the next copy of a standard component. 

### Reuse is not always cheap

Automating processes and standardising components is expensive, but it
pays off when the frequency of usage is high. Components that are used
rarely and obscure processes may not always benefit from
standardisation or automation. However, a complex process can still
benefit from use of standards and automation if mistakes are frequent
and expensive.


## Autonomy

### Centralization, pull-based workflows


- clients know when it's the best time to pull updates
- clients are responsible for staying updated
- having a central place (canonical name) to refer to infra resources is still very
  much beneficial
    - centralized names (dns) does not mean single point of failure, the gold server
      is not mission critical, it being down does not impact the users of the infrastructure
- gold server is passive
- When pushing configuration from a central server to hundreds, perhaps thousands of
  clients,
  the load is concentrated in the server pushing all these changes
    - the clients must stop anything they're doing to accept the changes, or consideration
      of the request. When there are network issues, clients may not even get the
      commands from the central server.
- By making the configuration server passive and the clients autonomous, it is
  possible to distribute the workload across all the different clients. Clients are
  more likely to choose an appropriate time to pull the updates from the central server.
- pull methods scale better, the computation needed is distributed to the clients, no
  need for a central powerful node to push changes to however many nodes you have
- having autonomous clients, and pull based workflows does not make the idea of
  centralized artefact repositories/servers irrelevant
    - Even when the workload to update the clients is distributed across the clients,
      there is
      still centralization, the golden server is the central point where all clients get
      their configuration.
    - Centralization does not mean single copy, the golden server
      may be replicated for higher availability, improving the performance of the
      updates across large appointments.


### Pull is better than Push




## Bringing it all together

[![Building IT infrastructure](/assets/svg/mindmap-building-it-infra.svg)](/assets/svg/mindmap-building-it-infra.svg)

<div style="text-align: center">
    <figcaption></figcaption>
</div>

[![Building IT infrastructure](/assets/svg/uml-building-it-infra.svg)](/assets/svg/uml-building-it-infra.svg)

Figure caption: Diagram sources:
Principles for building
infrastructures: [link](../assets/diagram/uml-building-it-infra.puml)
The idea is to derive each of the key ideas/concepts in the article from first
principles, that should be accepted as self-evident

## Related

1. Traugott, S. and Joel Huddleston. <a name="traugott98">Bootstrapping an 
   Infrastructure. LISA (1998).</a>
    - [Semantic Scholar - CorpusID:30764312](https://api.semanticscholar.org/CorpusID:30764312)
    - [infrastructures.org - papers](http://www.infrastructures.org/papers/bootstrap/bootstrap.html)
    - [usenix.org - Abstracts - 12th Systems Administration Conference (LISA '98)](https://www.usenix.org/legacy/publications/library/proceedings/lisa98/traugott.html)
2. [infrastructures.org](http://www.infrastructures.org) (_Retrieved on 2022-09-04 20:59_)
3. Burgess, Mark, <a id="cm-burgess" href="http://markburgess.org/cm.html"> 
   Configuration management, models and myths</a>.
   (_Retrieved on 2022-09-04 20:38_)
4. <a id="gitops" href="https://about.gitlab.com/topics/gitops/">
   What is GitOps? | GitLab
   </a>

## Footnotes
